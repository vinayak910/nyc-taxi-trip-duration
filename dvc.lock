schema: '2.0'
stages:
  extract_dataset:
    cmd: python .\src\data\extract_dataset.py
    deps:
    - path: .\data\raw\zipped
      hash: md5
      md5: 2ac9e57fc0bc2d2a1a610a695529d479.dir
      size: 87295035
      nfiles: 2
    - path: .\src\data\extract_dataset.py
      hash: md5
      md5: b0471292bcbcb0dc5a74fbef4532019d
      size: 1169
    outs:
    - path: .\data\raw\extracted
      hash: md5
      md5: 07dcb976ec534725901d50758a399273.dir
      size: 271383386
      nfiles: 2
  make_dataset:
    cmd: python .\src\data\make_dataset.py train.csv
    deps:
    - path: .\data\raw\extracted\train.csv
      hash: md5
      md5: e59c291a4b1c640f1dab33b89daa22e1
      size: 200589097
    - path: .\src\data\make_dataset.py
      hash: md5
      md5: 076eeb3118349a7d21a88a87f8d221d1
      size: 3282
    params:
      params.yaml:
        make_dataset.random_state: 30
        make_dataset.test_size: 0.2
    outs:
    - path: .\data\interim
      hash: md5
      md5: a366f7220347515a71e07aa8789073f8.dir
      size: 197004804
      nfiles: 2
